# Speech-Recognition---Final-Project

### Links
trello == https://trello.com/b/3DAn0eSU/final-project-speech-recognition

GitHub Repo == https://github.com/gastryphon/Speech-Recognition---Final-Project

Dataset == The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)
           https://zenodo.org/record/1188976

## Overview

Understanding human emotion is essential in understanding a situation it is in. Through verbal, tonal, non-verbal factors, we can guess the emotional state of a human and act in accordance to that feedback. 

Though human communication is mostly non-verbal, remote communications & the recent evolutions of machine learning allow to challenge the subjectivity of emotion reading through the study of speech patterns.

Speech recognition tools such as Siri or connected home speakers bring about a need and possibility to better label human emotion in order to both understand situational patterns and emotional profiles of a persona. 

## Use Case

From call-center response fitting to customer satisfaction feedback, speech emotion recognition can be a valuable tool
for many industries. The study of voice tone is universal and goes beyond language barrier, it could be added to textual positivity readers and more advanced visual body-language and facial expression reading tools to have a complete and trustworthy feedback of a person's emotional state.


## DataSet

## Libraries

- Python
- Librosa
- Soundfile
- Numpy
- Keras
- Sklearn
- Pandas

## Models
