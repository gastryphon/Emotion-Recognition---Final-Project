# Speech-Emotion-Recognition / Final-Project

## Overview

Understanding human emotion is essential in understanding a situation it is in. Through verbal & non-verbal factors, we can guess the emotional state of a human and act in accordance to that feedback. 

Speech recognition tools such as Siri or connected home speakers bring about a need and possibility to better label human emotion in order to both understand situational patterns and emotional profiles of a persona. 

Though human communication is mostly non-verbal, remote communications & the recent evolutions of machine learning allow to challenge the subjectivity of emotion reading through the study of speech patterns.

## Use Case

The study of voice features is universal and goes beyond language analysis. Coupled with text sentiment for a given language, visual body-language and facial expression reading tools it can provide a complete and trustworthy feedback of a person's emotional state.

From call-center response to customer satisfaction, speech emotion recognition by itself can be a valuable tool
for many industries. 

The interest and goal of such a speech emotion recognition tool is therefore to provide feedback on a locutor's emotional state at the moment of recording, whether analysed after-the-fact or in real time.

Further work on the subject could extend analysis to more speech databases, and couple the speech analysis to visual video recordings.

## DataSet

The dataset used here is an audio sample of the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS), 
consisting of songs and regular speech recordings of 24 actors with equal gender parity. 

The emotions conveyed were each confirmed by 247 individuals.

Speeches includes calm, happy, sad, angry, fearful, surprise, and disgust, and songs calm, happy, sad, angry, and fearful emotions,
expressed at neutral, 'regular' and high intensity.

## Libraries

- Python
- Librosa
- Soundfile
- Numpy
- Keras
- Sklearn
- Pandas

## Models


### Links

Trello: https://trello.com/b/3DAn0eSU/final-project-speech-recognition

GitHub Repo: https://github.com/gastryphon/Speech-Recognition---Final-Project

Dataset: The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)
           https://zenodo.org/record/1188976
